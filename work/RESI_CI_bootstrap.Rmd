---
title: "Simulation analysis evaluating bootstrapped CIs for RESI in a simple scenario"
author: "Kaidi Kang"
date: "6/29/2021"
output: 
  html_document:
    toc: true
    number_sections: true
    use_bookdown: yes
    code_folding: hide
    toc_float: 
      collapsed: false

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract
This report is used to summarize the performances of CIs for RESI constructed via different bootstraps.\

Simple case situations will be considered:\

  + only 1 covariate and no nuisance covariates
  + Std Normal distribution

```{r}
# packages
library(magrittr)
library(lattice)
# devtools::install_github("cran/car")
library(car)
library(parallel)
# source functions
source("../R/boot.ci.R")
source("../R/nccd.R")
source("../R/ncf.R")
source("../R/S.R")
```


# Simulations

```{r,eval=FALSE}
SimFunc <- function(n = 100, r = 1000, alpha = 0.05, m = 1, S = 0.6, shape, hetero = TRUE, method, multi, boot.type, fixed_rv, pi = 0.3, num.cores = 10){
  
  # simulate x and y
  if (fixed_rv) {
    sequence = rep(0:1, times = m*c(n - ceiling(n*pi), ceiling(n*pi)))
    x = sample(sequence, replace = FALSE) %>% matrix(nrow = n, ncol = m)
  } else {
    x = rbinom(n*m, 1, pi) %>% matrix(nrow = n, ncol = m)
    sum(x)
  }
  xTx = sum(x^2)

  if (hetero) {
    errors = (rgamma(n, shape = shape, rate = sqrt(shape)/ (x[,1] + 0.5) ) - sqrt(shape) * (x[, 1] + 0.5))/sqrt(0.5^2*(1-pi) + 1.5^2*pi)  # depends on the 1st covariate
    var(errors)
  } else {
    errors = rgamma(n, shape =  shape, rate = sqrt(shape) ) - sqrt(shape)
  }
  # true beta
  beta = sqrt(S^2/pi/(1-pi))
  
  # generate values of y -- intercept
  y = 1 + x %*% beta + errors
  
  # fit the model
  model <- lm(y ~ x)
  # estimated beta
  beta.hat <- coef(model)
  
  # 1. when sigma is known (sigma = 1)
  # S.hat.norm <- sqrt(beta.hat^2/(n*xTx*sigma2))
  # bias.norm <- S.hat.norm - S
  # 
  # # CIs
  # ## 1. thru non-central Chi-sq
  # S.CI.

  # when sigma in unknwon
  # 2. naive estimator for sigma^2
  ## obtain CI by using a bootstrap method
  result <- boot.ci(model.full = lm(y ~ x) , r = r, method  = method, multi = multi, boot.type = boot.type, num.cores = num.cores)$anova %>% as.matrix
  S.CI.boot = c(result[1, 5:6])
  S.hat = result[1, 4]
  bias <- S.hat - S
  # the statistic
  stat = result[1, 2]
  df = result[1, 1]
  res.df = result[3, 1]
  # obtain CI by using non-central Chi-sq dist
  S.CI.chi <- ncc.ints(sqrt(stat), df, alpha = alpha)[1, ]/sqrt(res.df)
  # CI via non-central F dist
  S.CI.f <- sqrt(ncf.ci(stat, df1 = df, df2 = res.df)/res.df)
  
  # # 3. using HC3 estimator
  # result.robust = boot.ci(model.full = lm(y ~ x) , r = r, method  = "Chisq", multi = multi, boot.type = boot.type, num.cores = num.cores)$anova %>% as.matrix
  # S.CI.robust = result.robust[1, 5:6]
  # S.hat.robust = result.robust[1, 4]
  # bias.robust <- S.hat.robust - S

  output = c(
             S.hat, bias,
             S.CI.boot,
             coverage.boot = (S >= S.CI.boot[1] & S <= S.CI.boot[2]),
             # the probabilty/proportion of true S failling on the left or right of the CI
             LL.boot.prob = S < S.CI.boot[1],
             UL.boot.prob = S > S.CI.boot[2],
             
             S.CI.chi,
             coverage.chi = (S >= S.CI.chi[1] & S <= S.CI.chi[2]),
             # the probabilty/proportion of true S failling on the left or right of the CI
             LL.chi.prob = S < S.CI.chi[1],
             UL.chi.prob = S > S.CI.chi[2],
             
             S.CI.f,
             coverage.f = (S >= S.CI.f[1] & S <= S.CI.f[2]),
             # the probabilty/proportion of true S failling on the left or right of the CI
             LL.f.prob = S < S.CI.f[1],
             UL.f.prob = S > S.CI.f[2]
             # beta.cvg.t, 
             # robust
             # S.hat.robust, bias.robust,
             # S.CI.robust,
             # coverage.robust = (S >= S.CI.robust[1] & S <= S.CI.robust[2]),
             # # the probabilty/proportion of true S failling on the left or right of the CI
             # LL.prob.robust = S < S.CI.robust[1],
             # UL.prob.robust = S > S.CI.robust[2]
             # beta.cvg.robust
             )
  
  name_list1 = c("LL.", "UL.", "coverage.", "LL.prob.", "UL.prob.")
  name_list2 = c("boot", "chi", "f")
  
  names(output) = c("S.hat", "Bias", paste0(rep(name_list1, times = length(name_list2)),
                    rep(name_list2, each = length(name_list1))) )
  
  return(output)
} # end of SimFunc()

# test
SimFunc(multi = 'none', shape = 100, method = "F", boot.type = 1, num.cores = 1, fixed_rv = FALSE, hetero = FALSE)

# 50 0 none 1 Chisq TRUE TRUE 0.1
SimFunc(n = 50, S = 0, multi = "none", boot.type = 1, method = "Chisq", fixed_rv = TRUE, hetero = TRUE, shape = 0.1)
```


```{r, eval=FALSE}
set.seed(1213)
nsim = 100 # outter loop
r = 500 # inner loop
alpha = 0.05
ns = c(50, 100, 250)
# ns = 200
Ss = c(0, 0.33, 0.66, 1)
# Ss = c(0, 0.6)
# shapes = c(0.1, 100) # skewness
shapes = c(0.1, 100)
# heteros = c(TRUE, FALSE) # hetero/homo-skedasticity
heteros = c(TRUE, FALSE)

methods = c("F", "Chisq") # F -> naive estimator for S; Chisq -> HC3 estimator for S
multis = c('none', 'rad', 'normal')
# multis = c("normal")
boot.types = 1:4
fixeds = c(TRUE, FALSE) # simulate fixed covariates?
# fixeds = FALSE

num.cores = 44

# n = 50; S = 0; multi = 'none'; boot.type = 1; method = "F"; fixed = FALSE; hetero = TRUE; shape = 0.1

out = expand.grid(n = ns, S = Ss, shape = shapes, hetero = heteros, 
                  method = methods, multi = multis, boot.type = boot.types,
                  fixed_rv = fixeds)
names <- SimFunc(n = 100, S = 0.1, r = 100, shape = shapes[1], hetero = FALSE,
                 multi = 'none', method = "F", boot.type = 1, num.cores = 1, fixed_rv = FALSE) %>% names()

# function(n = 100, r = 1000, alpha = 0.05, m = 1, S = 0.6, shape, hetero = TRUE, sigma2 = 0.2, method, multi, boot.type, fixed_covariate, pi = 0.3, num.cores = 10){

for (n in ns){
  for (S in Ss){
    for (multi in multis) {
      for (boot.type in boot.types){
        for (method in methods) {
          for (fixed in fixeds){
            for (hetero in heteros){
              for (shape in shapes){
                
                if (multi == 'none' & boot.type == 4) next
        
                message(paste(n, S, multi, boot.type, method, fixed, hetero, shape), collapse = ";")
                
                temp <- simplify2array(
                  mclapply(1:nsim, function(simInd, n, r, S, shape, hetero, method, multi, boot.type, fixed_rv){ 
                                            SimFunc(n = n, r = r, S = S, shape = shape,  
                                                    hetero = hetero,
                                                    method = method,
                                                    multi = multi, boot.type = boot.type, 
                                                    fixed_rv = fixed,
                                                    num.cores = 1) 
                                            }, 
                           n = n, r = r, S = S, shape = shape, 
                           hetero = hetero,
                           method = method,
                           multi = multi, boot.type = boot.type,
                           fixed = fixed, 
                           mc.cores = num.cores)
                ) %>% t()
                
                out[which(out$n == n 
                          & out$S == S
                          & out$multi == multi 
                          & out$boot.type == boot.type 
                          & out$method == method
                          & out$fixed_rv == fixed
                          & out$hetero == hetero
                          & out$shape == shape), names] <- colMeans(temp)
              }
              
            }
          }
        }
      }
    }
  }
}
```

```{r}
# write.csv(out, "Simulation outputs/CIs_Simple_Case_bootstrap_Jul13.csv")
```


# Plots

+ Bootstrap types: 

  1: resampling covariates along with residuals;
  2: fixing covariates and only bootstrapping residulas;
  3: resampling covariates and residuals independently w/ replacements
  4. no sampling, just multipliers

+ Estimators: 1) using naive var estimator (homoskedasticity); 2) using robust var-cov estimator (HC3, heteroskedasticity)
+ CI methods: 1) using non-central Chi-square dist; 2) using singly non-central F-dist; 3) non-parametric bootstraps (boot.type = 1 & multiplier = "none")

```{r}
# out <- read.csv("Simulation outputs/CIs_Simple_Case_bootstrap_Jul13.csv", header = TRUE)
out$S_lab = paste("S =", out$S) # convert to label string
out$boot.type_lab <- paste("Bootstrap = ", out$boot.type)
```


## Figure 1A. Homoskedasticity + Normal + Random r.v.
```{r}
data.plot = subset(out, hetero == FALSE & shape == 100 & boot.type == 1 & multi == 'none' & fixed_rv == FALSE)
```

```{r}
trellis.device(color=FALSE, new=FALSE)

test = xyplot(coverage.f + coverage.chi + coverage.boot ~ n | S_lab * method , 
              data= data.plot,
              type='b', lwd=2, 
              ylab='Coverage', xlab = 'Sample size',
              # ylim = c(0.60, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='CI coverage under homoskedasticity, normal residual and Random covariate(s)',
              key = list(columns = 3,
                         text = list(lab = c( "F CI", "Non-para boot CI", "Chi CI")),
                         points = list(pch = 1:3))
              # I don't know why but the function xyplot() automatically selects `pch`, so I had to manually select the corresponding `pch` for each label
              )
print(test)
```

## Figure 1B. Homoskedasticity + Normal + fixed r.v.
```{r}
data.plot = subset(out, hetero == FALSE & shape == 100 & boot.type == 1 & multi == 'none' & fixed_rv == TRUE)
```

```{r}
trellis.device(color=FALSE, new=FALSE)

test = xyplot(coverage.f + coverage.chi + coverage.boot ~ n | S_lab * method , 
              data= data.plot,
              type='b', lwd=2, 
              ylab='Coverage', xlab = 'Sample size',
              # ylim = c(0.60, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='CI coverage under homoskedasticity, normal residual and fixed covariate(s)',
              key = list(columns = 3,
                         text = list(lab = c( "F CI", "Non-para boot CI", "Chi CI")),
                         points = list(pch = 1:3))
              # I don't know why but the function xyplot() automatically selects `pch`, so I had to manually select the corresponding `pch` for each label
              )
print(test)
```


## Figure 2A. Homoskedasticity + Normal (+ Random r.v.)

```{r}
data.plot = subset(out, hetero == FALSE & shape == 100 & boot.type == 1 & multi == 'none' & fixed_rv == FALSE)
```

```{r}
trellis.device(color=FALSE, new=FALSE)


test = xyplot(coverage.f + coverage.chi + coverage.boot ~ n | S_lab * method , 
              data= data.plot,
              type='b', lwd=2, 
              ylab='Coverage', xlab = 'Sample size',
              # ylim = c(0.60, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='CI coverage under homoskedasticity, normal residual',
              key = list(columns = 3,
                         text = list(lab = c( "F CI", "Non-para boot CI", "Chi CI")),
                         points = list(pch = 1:3))
              # I don't know why but the function xyplot() automatically selects `pch`, so I had to manually select the corresponding `pch` for each label
              )
print(test)
```

## Figure 2B. Heterskedasticity + Normal + (Rnadom r.v)

```{r}
data.plot = subset(out, hetero == TRUE & shape == 100 & boot.type == 1 & multi == 'none' & fixed_rv == FALSE)
```

```{r}
trellis.device(color=FALSE, new=FALSE)
test = xyplot(coverage.f + coverage.chi + coverage.boot ~ n | S_lab * method , 
              data= data.plot,
              type='b', lwd=2, 
              ylab='Coverage', xlab = 'Sample size',
              # ylim = c(0.60, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='Heteroskedasticity, normal residual',
              key = list(columns = 3,
                         text = list(lab = c( "F CI", "Non-para boot CI", "Chi CI")),
                         points = list(pch = 1:3))
              # I don't know why but the function xyplot() automatically selects `pch`, so I had to manually select the corresponding `pch` for each label
              )
print(test)
```

## Figure 3A. Homoskedasticity + Skewed + (Rnadom r.v)

```{r}
data.plot = subset(out, hetero == FALSE & shape == 0.1 & boot.type == 1 & multi == 'none' & fixed_rv == FALSE)
```

```{r}
trellis.device(color=FALSE, new=FALSE)
test = xyplot(coverage.f + coverage.chi + coverage.boot ~ n | S_lab * method , 
              data= data.plot,
              type='b', lwd=2, 
              ylab='Coverage', xlab = 'Sample size',
              # ylim = c(0.60, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='Homoskedasticity, normal residual',
              key = list(columns = 3,
                         text = list(lab = c( "F CI", "Non-para boot CI", "Chi CI")),
                         points = list(pch = 1:3))
              # I don't know why but the function xyplot() automatically selects `pch`, so I had to manually select the corresponding `pch` for each label
              )
print(test)
```

## Figure 3B. Heteroskedasticity + Skewed + (Rnadom r.v)

```{r}
data.plot = subset(out, hetero == TRUE & shape == 0.1 & boot.type == 1 & multi == 'none' & fixed_rv == FALSE)
```

```{r}
trellis.device(color=FALSE, new=FALSE)
test = xyplot(coverage.f + coverage.chi + coverage.boot ~ n | S_lab * method , 
              data= data.plot,
              type='b', lwd=2, 
              ylab='Coverage', xlab = 'Sample size',
              # ylim = c(0.60, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='Heteroskedasticity, normal residual',
              key = list(columns = 3,
                         text = list(lab = c( "F CI", "Non-para boot CI", "Chi CI")),
                         points = list(pch = 1:3))
              # I don't know why but the function xyplot() automatically selects `pch`, so I had to manually select the corresponding `pch` for each label
              )
print(test)
```


## S = 0.1

```{r, fig.height=7}
# S = 0.1
trellis.device(color=FALSE, new=FALSE)

test = xyplot(coverage.t + coverage.robust ~ n | multi*boot.type_lab , 
              data= subset(out, S == 0.1),
              type='b', lwd=2,
              ylab='Coverage', xlab = 'Sample size',
              ylim = c(0.85, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='CI coverage (S = 0.1)',
              key = list(columns = 2,
                         text = list(lab = c( "t", "robust")),
                         points = list(pch =c(3, 6)))
              )
print(test)
```

## S = 0.4

```{r, fig.height=7}
# S = 0.4
trellis.device(color=FALSE, new=FALSE)

test = xyplot(coverage.t + coverage.robust ~ n | multi*boot.type_lab , 
              data= subset(out, S == 0.4),
              type='b', lwd=2,
              ylab='Coverage', xlab = 'Sample size',
              ylim = c(0.85, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='CI coverage (S = 0.4)',
              key = list(columns = 2,
                         text = list(lab = c( "t", "robust")),
                         points = list(pch =c(3, 6)))
              )
print(test)
```








## S = 0.66 (Homoskedasticity, Normal, Random r.v. and with Robust RESI Estimator used)

```{r, fig.height=7}
# S = 0.6
data = subset(out, S == 0.66 & hetero == FALSE & shape == 0.1 & fixed_rv == FALSE & method == "Chisq")
trellis.device(color=FALSE, new=FALSE)

test = xyplot(coverage.f + coverage.chi ~ n | multi * boot.type_lab , 
              data= data,
              type='b', lwd=2,
              ylab='Coverage', xlab = 'Sample size',
              # ylim = c(0.85, 1.02),
              panel= function(x, y, ...){
                panel.grid()
                panel.xyplot(x, y, ..., col='black')
                panel.abline(h=0.95, col='gray', ..., lty=2)
                }, 
              main='CI coverage (S = 0.6)',
              key = list(columns = 2,
                         text = list(lab = c( "F estimator", "Chi-sq estimator")),
                         points = list(pch =c(1, 3)))
              )
print(test)
```
